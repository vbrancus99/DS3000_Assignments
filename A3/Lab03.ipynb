{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 3.1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>PERIMETER</th>\n",
       "      <th>MAJORAXIS</th>\n",
       "      <th>MINORAXIS</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>CONVEX_AREA</th>\n",
       "      <th>EXTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15231</td>\n",
       "      <td>525.578979</td>\n",
       "      <td>229.749878</td>\n",
       "      <td>85.093788</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>15617</td>\n",
       "      <td>0.572896</td>\n",
       "      <td>Cammeo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14656</td>\n",
       "      <td>494.311005</td>\n",
       "      <td>206.020065</td>\n",
       "      <td>91.730972</td>\n",
       "      <td>0.895405</td>\n",
       "      <td>15072</td>\n",
       "      <td>0.615436</td>\n",
       "      <td>Cammeo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14634</td>\n",
       "      <td>501.122009</td>\n",
       "      <td>214.106781</td>\n",
       "      <td>87.768288</td>\n",
       "      <td>0.912118</td>\n",
       "      <td>14954</td>\n",
       "      <td>0.693259</td>\n",
       "      <td>Cammeo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13176</td>\n",
       "      <td>458.342987</td>\n",
       "      <td>193.337387</td>\n",
       "      <td>87.448395</td>\n",
       "      <td>0.891861</td>\n",
       "      <td>13368</td>\n",
       "      <td>0.640669</td>\n",
       "      <td>Cammeo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14688</td>\n",
       "      <td>507.166992</td>\n",
       "      <td>211.743378</td>\n",
       "      <td>89.312454</td>\n",
       "      <td>0.906691</td>\n",
       "      <td>15262</td>\n",
       "      <td>0.646024</td>\n",
       "      <td>Cammeo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AREA   PERIMETER   MAJORAXIS  MINORAXIS  ECCENTRICITY  CONVEX_AREA  \\\n",
       "0  15231  525.578979  229.749878  85.093788      0.928882        15617   \n",
       "1  14656  494.311005  206.020065  91.730972      0.895405        15072   \n",
       "2  14634  501.122009  214.106781  87.768288      0.912118        14954   \n",
       "3  13176  458.342987  193.337387  87.448395      0.891861        13368   \n",
       "4  14688  507.166992  211.743378  89.312454      0.906691        15262   \n",
       "\n",
       "     EXTENT   CLASS  \n",
       "0  0.572896  Cammeo  \n",
       "1  0.615436  Cammeo  \n",
       "2  0.693259  Cammeo  \n",
       "3  0.640669  Cammeo  \n",
       "4  0.646024  Cammeo  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This dataset describes grains of rice in terms of visual properties.\n",
    "# The class is the variety of rice, either Cammeo or OsmancÄ±k\n",
    "# https://archive.ics.uci.edu/ml/datasets/Rice+%28Cammeo+and+Osmancik%29\n",
    "# (Actually downloaded the data from the paper's website.)\n",
    "rice = pd.read_csv(\"Rice_Osmancik_Cammeo_Dataset.csv\")\n",
    "rice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Osmancik    2180\n",
       "Cammeo      1630\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out class distribution\n",
    "rice.CLASS.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5721784776902887\n"
     ]
    }
   ],
   "source": [
    "#Baseline accuracy?\n",
    "\n",
    "baselineAcc = 2180/(2180+1630)\n",
    "print(baselineAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data, train logistic regression\n",
    "X = rice.drop('CLASS', axis = 'columns').values\n",
    "y = rice.CLASS.values\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y, test_size = 0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [0.00318845] \n",
      "Coefficients: [[ 0.00608732  0.14475211 -0.24051264  0.39193589  0.00145249 -0.01007885\n",
      "   0.003195  ]]\n"
     ]
    }
   ],
   "source": [
    "# Fit model, print coefficients\n",
    "RICELR = LogisticRegression(penalty = 'none')\n",
    "ricelr = RICELR.fit(Xtrain, ytrain)\n",
    "\n",
    "print(f\"Intercept: {ricelr.intercept_} \\nCoefficients: {ricelr.coef_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.34226677],\n",
       "       [-10.37898789],\n",
       "       [ -0.09896634],\n",
       "       ...,\n",
       "       [ -4.0019276 ],\n",
       "       [  1.71460141],\n",
       "       [ -8.58612399]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict manually\n",
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "z = np.dot(Xtest,ricelr.coef_.T) + ricelr.intercept_\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.65850686e-01],\n",
       "       [3.10777332e-05],\n",
       "       [4.75278589e-01],\n",
       "       ...,\n",
       "       [1.79521950e-02],\n",
       "       [8.47432156e-01],\n",
       "       [1.86643411e-04]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.41493136e-02, 9.65850686e-01],\n",
       "       [9.99968922e-01, 3.10777332e-05],\n",
       "       [5.24721411e-01, 4.75278589e-01],\n",
       "       ...,\n",
       "       [9.82047805e-01, 1.79521950e-02],\n",
       "       [1.52567844e-01, 8.47432156e-01],\n",
       "       [9.99813357e-01, 1.86643411e-04]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test\n",
    "ricelr.predict_proba(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Osmancik', 'Cammeo', 'Cammeo', ..., 'Cammeo', 'Osmancik',\n",
       "       'Cammeo'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get label predictions - how does this function work?\n",
    "ytest_hat = ricelr.predict(Xtest)\n",
    "ytest_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 3.2 - Evaluating Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 1001 tn: 773 fp: 81 fn: 50\n",
      "Accuracy: 0.931 Recall: 0.952 Precision: 0.925 Sensitivity: 0.952 Specificity: 0.905\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance measures from scratch\n",
    "# TP: true postives \n",
    "# TN: true negatives \n",
    "# FP: False positives \n",
    "# FN: False negatives\n",
    "def compute_performance(yhat, y, classes):\n",
    "    # First, get tp, tn, fp, fn\n",
    "    tp = sum(np.logical_and(yhat == classes[1], y == classes[1]))\n",
    "    tn = sum(np.logical_and(yhat == classes[0], y == classes[0]))\n",
    "    fp = sum(np.logical_and(yhat == classes[1], y == classes[0]))\n",
    "    fn = sum(np.logical_and(yhat == classes[0], y == classes[1]))\n",
    "\n",
    "    print(f\"tp: {tp} tn: {tn} fp: {fp} fn: {fn}\")\n",
    "    \n",
    "    # Accuracy\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    # Precision\n",
    "    # \"Of the ones I labeled +, how many are actually +?\"\n",
    "    precision = tp / (tp + fp)\n",
    "    \n",
    "    # Recall\n",
    "    # \"Of all the + in the data, how many do I correctly label?\"\n",
    "    recall = tp / (tp + fn)    \n",
    "    \n",
    "    # Sensitivity\n",
    "    # \"Of all the + in the data, how many do I correctly label?\"\n",
    "    sensitivity = recall\n",
    "    \n",
    "    # Specificity\n",
    "    # \"Of all the - in the data, how many do I correctly label?\"\n",
    "    specificity = tn / (fp + tn)\n",
    "    \n",
    "    # Print results\n",
    "    \n",
    "    print(\"Accuracy:\",round(acc,3),\"Recall:\",round(recall,3),\"Precision:\",round(precision,3),\n",
    "          \"Sensitivity:\",round(sensitivity,3),\"Specificity:\",round(specificity,3))\n",
    "\n",
    "compute_performance(ytest_hat, ytest, ricelr.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 1040 tn: 613 fp: 241 fn: 11\n",
      "Accuracy: 0.868 Recall: 0.99 Precision: 0.812 Sensitivity: 0.99 Specificity: 0.718\n"
     ]
    }
   ],
   "source": [
    "# Now let's experiment by adjusting the decision threshold\n",
    "ytest_prob = ricelr.predict_proba(Xtest)\n",
    "yhat = ricelr.classes_[(ytest_prob[:,1]>0.1).astype(int)]\n",
    "\n",
    "compute_performance(yhat, ytest, ricelr.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VBran\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC using sklearns ROC curve. \n",
    "fpr, tpr, _ = roc_curve(ytest, ytest_prob[:,1], pos_label=\"Osmancik\")\n",
    "ax = sns.lineplot(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9801115030404856"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUROC\n",
    "auc(fpr,tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 3.3 - Multiclass Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal-length</th>\n",
       "      <th>Sepal-width</th>\n",
       "      <th>Petal-length</th>\n",
       "      <th>Petal-width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal-length  Sepal-width  Petal-length  Petal-width      Species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "iris = pd.read_csv(\"iris.csv\")\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iris-setosa        50\n",
       "Iris-versicolor    50\n",
       "Iris-virginica     50\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out class distribution\n",
    "iris.Species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create y and X. Not going to split these data for this demonstration.\n",
    "y = iris.Species.values\n",
    "X = iris.drop(\"Species\", axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercepts: [ 2.19258938  0.21853297 -2.41112235] \n",
      "Coefficients: [[-0.13682448  0.096067   -0.43483505 -0.17832092]\n",
      " [-0.00099744 -0.10239728  0.08665839 -0.00340217]\n",
      " [ 0.13782191  0.00633028  0.34817665  0.18172309]]\n"
     ]
    }
   ],
   "source": [
    "# Note that unlike our convention in class, sklearn makes a parameter vector\n",
    "# for every class (not just first K-1) even though it is redundant.\n",
    "# Try this with regularization too\n",
    "\n",
    "IRISLR = LogisticRegression(penalty = 'l2', solver = 'newton-cg', C = 0.01) # param C controls how much regularization is happening, defult is 1\n",
    "irislr = IRISLR.fit(X,y)\n",
    "print(f\"Intercepts: {irislr.intercept_} \\nCoefficients: {irislr.coef_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71766415, 0.21381534, 0.06852052],\n",
       "       [0.70685501, 0.22633209, 0.0668129 ],\n",
       "       [0.7323165 , 0.20817581, 0.05950769],\n",
       "       [0.70881893, 0.22505227, 0.06612879],\n",
       "       [0.7245337 , 0.2087652 , 0.0667011 ],\n",
       "       [0.6742779 , 0.23405299, 0.0916691 ],\n",
       "       [0.72673576, 0.20999816, 0.06326608],\n",
       "       [0.70560892, 0.22286924, 0.07152184],\n",
       "       [0.72030284, 0.21981415, 0.05988301],\n",
       "       [0.70288995, 0.22842071, 0.06868934],\n",
       "       [0.70207957, 0.22060249, 0.07731794],\n",
       "       [0.70047473, 0.22684486, 0.07268041],\n",
       "       [0.71474133, 0.22185497, 0.0634037 ],\n",
       "       [0.76385167, 0.18944813, 0.0467002 ],\n",
       "       [0.73426157, 0.19627652, 0.06946191],\n",
       "       [0.70638392, 0.20836292, 0.08525316],\n",
       "       [0.72403102, 0.2040045 , 0.07196447],\n",
       "       [0.71318185, 0.21622929, 0.07058886],\n",
       "       [0.66396841, 0.24062566, 0.09540594],\n",
       "       [0.71166627, 0.21418113, 0.0741526 ],\n",
       "       [0.66557443, 0.24636251, 0.08806305],\n",
       "       [0.70353362, 0.21978877, 0.07667761],\n",
       "       [0.78013931, 0.17281579, 0.0470449 ],\n",
       "       [0.65833121, 0.25149817, 0.09017063],\n",
       "       [0.66228663, 0.25079968, 0.08691369],\n",
       "       [0.67848146, 0.24442691, 0.07709163],\n",
       "       [0.68380187, 0.23564476, 0.08055337],\n",
       "       [0.70209795, 0.2233893 , 0.07451275],\n",
       "       [0.71069135, 0.21893577, 0.07037288],\n",
       "       [0.69677311, 0.23161535, 0.07161153],\n",
       "       [0.6895118 , 0.23699313, 0.07349508],\n",
       "       [0.68169054, 0.2354302 , 0.08287926],\n",
       "       [0.727502  , 0.20192359, 0.07057441],\n",
       "       [0.72788599, 0.19927012, 0.0728439 ],\n",
       "       [0.69831679, 0.23093898, 0.07074423],\n",
       "       [0.73386932, 0.20625224, 0.05987844],\n",
       "       [0.71575755, 0.213713  , 0.07052945],\n",
       "       [0.73221421, 0.204523  , 0.06326279],\n",
       "       [0.73520856, 0.20877751, 0.05601393],\n",
       "       [0.70207093, 0.22478429, 0.07314478],\n",
       "       [0.72836146, 0.20678266, 0.06485588],\n",
       "       [0.70272365, 0.23653075, 0.0607456 ],\n",
       "       [0.74197612, 0.20249984, 0.05552403],\n",
       "       [0.67781319, 0.23714369, 0.08504313],\n",
       "       [0.65571609, 0.24740585, 0.09687806],\n",
       "       [0.70582485, 0.22688745, 0.0672877 ],\n",
       "       [0.70409249, 0.21937447, 0.07653304],\n",
       "       [0.72414177, 0.21394607, 0.06191215],\n",
       "       [0.70565778, 0.21873552, 0.07560671],\n",
       "       [0.71408854, 0.21837814, 0.06753332],\n",
       "       [0.13897506, 0.39222947, 0.46879547],\n",
       "       [0.16889432, 0.40283325, 0.42827243],\n",
       "       [0.121615  , 0.39012496, 0.48826004],\n",
       "       [0.23651765, 0.44404033, 0.31944202],\n",
       "       [0.14971712, 0.41286262, 0.43742026],\n",
       "       [0.18920449, 0.42897597, 0.38181954],\n",
       "       [0.15221151, 0.39658167, 0.45120682],\n",
       "       [0.36949089, 0.41287916, 0.21762995],\n",
       "       [0.15587049, 0.4124625 , 0.431667  ],\n",
       "       [0.26606971, 0.4278872 , 0.30604309],\n",
       "       [0.32310029, 0.43977303, 0.23712668],\n",
       "       [0.20998622, 0.41639018, 0.3736236 ],\n",
       "       [0.22998294, 0.44727876, 0.32273829],\n",
       "       [0.15730341, 0.41697405, 0.42572254],\n",
       "       [0.30002301, 0.41143806, 0.28853894],\n",
       "       [0.17117779, 0.40460269, 0.42421952],\n",
       "       [0.18872964, 0.42014347, 0.39112689],\n",
       "       [0.23928401, 0.43206665, 0.32864934],\n",
       "       [0.15488681, 0.43844877, 0.40666442],\n",
       "       [0.25976518, 0.43547064, 0.30476419],\n",
       "       [0.14575456, 0.40028778, 0.45395766],\n",
       "       [0.22898567, 0.42234227, 0.34867206],\n",
       "       [0.12620019, 0.42033779, 0.45346202],\n",
       "       [0.16254912, 0.42440593, 0.41304495],\n",
       "       [0.1895773 , 0.4175078 , 0.3929149 ],\n",
       "       [0.17207774, 0.40928547, 0.41863679],\n",
       "       [0.12966835, 0.40622299, 0.46410866],\n",
       "       [0.11197204, 0.38903531, 0.49899266],\n",
       "       [0.17447457, 0.41831594, 0.40720949],\n",
       "       [0.31528994, 0.41896568, 0.26574437],\n",
       "       [0.27276128, 0.43674989, 0.29048883],\n",
       "       [0.29040573, 0.43372101, 0.27587327],\n",
       "       [0.25336944, 0.4268627 , 0.31976786],\n",
       "       [0.11888015, 0.41267264, 0.4684472 ],\n",
       "       [0.1950018 , 0.42247241, 0.38252579],\n",
       "       [0.18107035, 0.40005553, 0.41887412],\n",
       "       [0.14160198, 0.39828304, 0.46011498],\n",
       "       [0.17007797, 0.43852137, 0.39140066],\n",
       "       [0.24068652, 0.4199749 , 0.33933859],\n",
       "       [0.24207621, 0.43678989, 0.3211339 ],\n",
       "       [0.20508219, 0.43916254, 0.35575527],\n",
       "       [0.16815708, 0.41478084, 0.41706207],\n",
       "       [0.23879633, 0.43234355, 0.32886011],\n",
       "       [0.36149753, 0.41767901, 0.22082346],\n",
       "       [0.22136606, 0.43190513, 0.34672881],\n",
       "       [0.23026159, 0.42164165, 0.34809676],\n",
       "       [0.22310977, 0.42408843, 0.3528018 ],\n",
       "       [0.19588268, 0.41983294, 0.38428437],\n",
       "       [0.40240329, 0.39419531, 0.2034014 ],\n",
       "       [0.23170864, 0.42643326, 0.3418581 ],\n",
       "       [0.05449466, 0.32736703, 0.61813831],\n",
       "       [0.11473622, 0.40849709, 0.47676669],\n",
       "       [0.05287374, 0.33260983, 0.61451643],\n",
       "       [0.08095999, 0.37814571, 0.54089429],\n",
       "       [0.06230844, 0.34897717, 0.58871439],\n",
       "       [0.02961646, 0.28724989, 0.68313366],\n",
       "       [0.1909501 , 0.44205302, 0.36699688],\n",
       "       [0.04180848, 0.32223986, 0.63595166],\n",
       "       [0.06263456, 0.37116877, 0.56619667],\n",
       "       [0.04342529, 0.29262027, 0.66395444],\n",
       "       [0.1041684 , 0.37585239, 0.5199792 ],\n",
       "       [0.09076369, 0.389126  , 0.52011031],\n",
       "       [0.07284692, 0.35712222, 0.57003087],\n",
       "       [0.11798686, 0.4164952 , 0.46551795],\n",
       "       [0.10267088, 0.39111064, 0.50621848],\n",
       "       [0.08702267, 0.36232728, 0.55065006],\n",
       "       [0.08379162, 0.37421372, 0.54199466],\n",
       "       [0.0287925 , 0.25893826, 0.71226925],\n",
       "       [0.02114515, 0.27255303, 0.70630182],\n",
       "       [0.12118635, 0.4333125 , 0.44550114],\n",
       "       [0.06090586, 0.33436044, 0.60473369],\n",
       "       [0.1321071 , 0.4114318 , 0.45646111],\n",
       "       [0.02719538, 0.28801204, 0.68479259],\n",
       "       [0.1204034 , 0.40618948, 0.47340711],\n",
       "       [0.06791253, 0.34347527, 0.5886122 ],\n",
       "       [0.05400588, 0.33086812, 0.615126  ],\n",
       "       [0.13153571, 0.40734961, 0.46111468],\n",
       "       [0.12959702, 0.400894  , 0.46950898],\n",
       "       [0.0724164 , 0.36858158, 0.55900202],\n",
       "       [0.06340272, 0.35161757, 0.58497971],\n",
       "       [0.04486276, 0.32780778, 0.62732945],\n",
       "       [0.03589538, 0.27391477, 0.69018985],\n",
       "       [0.07051276, 0.36522544, 0.56426181],\n",
       "       [0.11663277, 0.4062541 , 0.47711313],\n",
       "       [0.08989924, 0.40440643, 0.50569433],\n",
       "       [0.03835952, 0.30092011, 0.66072036],\n",
       "       [0.07339036, 0.34475574, 0.5818539 ],\n",
       "       [0.08653448, 0.37375777, 0.53970775],\n",
       "       [0.13974628, 0.40478808, 0.45546564],\n",
       "       [0.0769529 , 0.35584612, 0.56720098],\n",
       "       [0.06512789, 0.34284094, 0.59203117],\n",
       "       [0.08804297, 0.36056258, 0.55139444],\n",
       "       [0.11473622, 0.40849709, 0.47676669],\n",
       "       [0.05461866, 0.32831772, 0.61706361],\n",
       "       [0.06084963, 0.33005779, 0.60909259],\n",
       "       [0.08509374, 0.36446273, 0.55044353],\n",
       "       [0.10809492, 0.40679758, 0.4851075 ],\n",
       "       [0.09568244, 0.37844269, 0.52587487],\n",
       "       [0.08722287, 0.35785823, 0.5549189 ],\n",
       "       [0.11973188, 0.40007635, 0.48019177]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that sklearn uses rows to indicate truth, columns to indicate prediction, unlike our convention\n",
    "# So transpose it.\n",
    "\n",
    "yhat = irislr.predict(X)\n",
    "yhat_probs = irislr.predict_proba(X)\n",
    "yhat_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  0,  0],\n",
       "       [ 1, 32, 17],\n",
       "       [ 0,  1, 49]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yhat, y).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
